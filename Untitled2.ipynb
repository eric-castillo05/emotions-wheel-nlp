{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b84cafa6-57a6-43c0-863e-0d3ca22bb4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91d47dc-bb9f-481a-aa9a-38f57657fc19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'validation': 'data/validation-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e60243-34a6-4870-a498-f90200682a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pl.read_parquet('hf://datasets/Jsevisal/go_emotions_wheel/' + splits['train'])\n",
    "df_test = pl.read_parquet('hf://datasets/Jsevisal/go_emotions_wheel/' + splits['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629953aa-cf5d-4316-b4eb-f69e21850e35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bdda8b-0ce2-454e-8933-60e3d1d7d352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_train = list(nlp.pipe(df_train.select('text').to_series().to_list()))\n",
    "docs_test = list(nlp.pipe(df_test.select('text').to_series().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9a94df-7782-4f51-a687-d0f4a5bab2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(doc):\n",
    "    return [token.text.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c05c9145-0b26-4457-a759-7324db972f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_texts_train = [' '.join(preprocess_text(doc)) for doc in docs_train]\n",
    "processed_texts_test = [' '.join(preprocess_text(doc)) for doc in docs_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bab5aa-cd20-43b6-bd50-f424d91e5461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c4b12c-3441-4ed1-8287-24463a4ee537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_raw = df_train['labels'].to_list()\n",
    "y_test_raw = df_test['labels'].to_list()\n",
    "\n",
    "all_labels_combined = y_train_raw + y_test_raw\n",
    "all_unique_label_ids = sorted(list(set(item for sublist in all_labels_combined for item in sublist)))\n",
    "mlb = MultiLabelBinarizer(classes=all_unique_label_ids)\n",
    "mlb.fit(all_labels_combined)\n",
    "\n",
    "y_train_multilabel = mlb.transform(y_train_raw)\n",
    "y_test_multilabel = mlb.transform(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89dedf5a-0951-48ff-8ce4-b7e896dbd7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6814000-2e32-4bdf-a89b-8f883bfd8af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b12fbdcb-43f6-4f2e-bf6f-6a54987de358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = tfidf.fit_transform(processed_texts_train)\n",
    "x_test = tfidf.transform(processed_texts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "079e209c-0480-423c-98d4-d71ae5898c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiLabelNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_rate=0.5):\n",
    "        super(MultiLabelNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "        self.dropout_rate = nn.Dropout(dropout_rate)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_rate(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout_rate(x)\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dc34690e-d6d9-4467-bf2d-b5ef858cc3d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelNN(\n",
       "  (fc1): Linear(in_features=5000, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=9, bias=True)\n",
       "  (dropout_rate): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiLabelNN(input_dim=5000, output_dim=y_train_multilabel.shape[1])\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b0b7282f-4ce1-4639-a82e-e2d320792f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = np.sum(y_train_multilabel, axis=0) \n",
    "total = y_train_multilabel.shape[0]\n",
    "\n",
    "counts[counts == 0] = 1\n",
    "pos_weight = torch.tensor((total - counts) / counts, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "44d77e7a-44c4-4aee-88de-ea3d6cd90007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, pos_weight=None, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # BCE with logits\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, reduction='none', pos_weight=self.pos_weight\n",
    "        )\n",
    "        # Probabilities\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        pt = torch.where(targets == 1, probs, 1 - probs)\n",
    "        focal_weight = (1 - pt) ** self.gamma\n",
    "\n",
    "        loss = focal_weight * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2be88fa5-27b0-4f21-8b0f-3bb6d577019b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "focal_criterion = FocalLoss(gamma=2, pos_weight=pos_weight.to(device)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5ad9cef2-7e3e-4f52-a0b4-3f2b16b8dcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_tensor = torch.tensor(x_train.toarray(), dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(y_train_multilabel, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "845defeb-67e1-4bea-a7fd-d3a17de0b963",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.1862\n",
      "Epoch 2 | Loss: 0.2862\n",
      "Epoch 3 | Loss: 0.1306\n",
      "Epoch 4 | Loss: 0.1999\n",
      "Epoch 5 | Loss: 0.1331\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(5): \n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = focal_criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc4c7267-6f4c-4a3a-8d0b-af74b825670b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1650\n",
      "           1       0.18      0.58      0.28       474\n",
      "           2       0.23      0.71      0.35        98\n",
      "           3       0.24      0.59      0.35       677\n",
      "           4       0.34      0.61      0.44       379\n",
      "           5       0.50      0.83      0.63      1787\n",
      "           6       0.11      0.64      0.19        83\n",
      "           7       0.31      0.62      0.41       726\n",
      "           8       0.17      0.63      0.27       123\n",
      "\n",
      "   micro avg       0.39      0.72      0.51      5997\n",
      "   macro avg       0.32      0.67      0.41      5997\n",
      "weighted avg       0.47      0.72      0.55      5997\n",
      " samples avg       0.46      0.73      0.54      5997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.tensor(x_test.toarray(), dtype=torch.float32).to(device)\n",
    "    logits = model(test_tensor)\n",
    "    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_multilabel, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e6458-3d5e-4343-9d0d-5c73be12bf3d",
   "metadata": {},
   "source": [
    "# Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40aa8322-843e-40d3-bce6-84d6ae7d5799",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[K     |████████████████████████████████| 395 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic>=1.5.0\n",
      "  Downloading alembic-1.16.2-py3-none-any.whl (242 kB)\n",
      "\u001b[K     |████████████████████████████████| 242 kB 85.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (2.0.2)\n",
      "Collecting sqlalchemy>=1.4.2\n",
      "  Downloading sqlalchemy-2.0.41-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 61.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from optuna) (24.0)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tomli in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (2.0.1)\n",
      "Collecting Mako\n",
      "  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.12 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
      "Collecting greenlet>=1\n",
      "  Downloading greenlet-3.2.3-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\n",
      "\u001b[K     |████████████████████████████████| 580 kB 72.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Installing collected packages: greenlet, sqlalchemy, Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.16.2 colorlog-6.9.0 greenlet-3.2.3 optuna-4.4.0 sqlalchemy-2.0.41\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "08304e62-21b4-4e5c-b5b6-3c232d2c5213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f82e6682-83b2-495c-bea8-32b12c7475c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "X_tensor_test = torch.tensor(x_train.toarray(), dtype=torch.float32)\n",
    "Y_tensor_test = torch.tensor(y_train_multilabel, dtype=torch.float32)\n",
    "val_dataset = TensorDataset(X_tensor_test, Y_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6f6e44ac-2a56-421f-86b2-1b15c1c49f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-3)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])\n",
    "    early_stop_patience = trial.suggest_int('early_stop_patience', 2, 6)\n",
    "    max_length = trial.suggest_categorical('max_length', [32, 64, 128, 256])\n",
    "    gradient_clip = trial.suggest_uniform('gradient_clip', 0.5, 5.0)\n",
    "    eps = trial.suggest_loguniform('eps', 1e-10, 1e-6)\n",
    "    correct_bias = trial.suggest_categorical('correct_bias', [True, False])\n",
    "    \n",
    "    focal_gamma = trial.suggest_float('focal_gamma', 0.5, 5.0) \n",
    "    pos_weight = trial.suggest_categorical('pos_weight', [None, 1.0, 2.0, 5.0])\n",
    "        \n",
    "    model = MultiLabelNN(input_dim=5000, output_dim=y_train_multilabel.shape[1], dropout_rate=dropout_rate)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay, eps=eps)\n",
    "    \n",
    "    criterion = FocalLoss(gamma=focal_gamma, pos_weight=pos_weight)\n",
    "    \n",
    "    X_tensor = torch.tensor(x_train.toarray(), dtype=torch.float32)\n",
    "    Y_tensor = torch.tensor(y_train_multilabel, dtype=torch.float32)\n",
    "    train_dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = focal_criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ee0e03df-5a2b-4ed3-b6d8-88962099760c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 22:31:47,523] A new study created in memory with name: no-name-3c98fb04-7945-4a2c-a5a7-096542abbb5c\n",
      "/tmp/ipykernel_96/163229422.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-3)\n",
      "/tmp/ipykernel_96/163229422.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-1)\n",
      "/tmp/ipykernel_96/163229422.py:4: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
      "/tmp/ipykernel_96/163229422.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gradient_clip = trial.suggest_uniform('gradient_clip', 0.5, 5.0)\n",
      "/tmp/ipykernel_96/163229422.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform('eps', 1e-10, 1e-6)\n",
      "[I 2025-07-07 22:35:07,070] Trial 0 finished with value: 0.10636131465435028 and parameters: {'learning_rate': 0.0001321776145528204, 'weight_decay': 0.00022122660751399764, 'dropout_rate': 0.47291614814623884, 'batch_size': 16, 'early_stop_patience': 4, 'max_length': 128, 'gradient_clip': 1.7413597427664174, 'eps': 3.785080347362386e-08, 'correct_bias': False, 'focal_gamma': 4.887162479562218, 'pos_weight': 2.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:38:47,119] Trial 1 finished with value: 0.27483895421028137 and parameters: {'learning_rate': 1.1346873789418995e-05, 'weight_decay': 0.003657754524815875, 'dropout_rate': 0.1388513221399037, 'batch_size': 16, 'early_stop_patience': 5, 'max_length': 128, 'gradient_clip': 4.218962293174105, 'eps': 9.54142251696328e-09, 'correct_bias': True, 'focal_gamma': 2.5405756551981353, 'pos_weight': 5.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:42:31,047] Trial 2 finished with value: 0.2382027804851532 and parameters: {'learning_rate': 0.0009580411621419609, 'weight_decay': 0.09845688921024251, 'dropout_rate': 0.48015276891715586, 'batch_size': 16, 'early_stop_patience': 2, 'max_length': 64, 'gradient_clip': 2.4399168376861318, 'eps': 2.332977511117786e-09, 'correct_bias': False, 'focal_gamma': 3.219362779290866, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:50:48,678] Trial 3 finished with value: 0.11021319776773453 and parameters: {'learning_rate': 0.0009016153428204612, 'weight_decay': 5.767019173187155e-05, 'dropout_rate': 0.4679014192601382, 'batch_size': 8, 'early_stop_patience': 2, 'max_length': 32, 'gradient_clip': 1.1106519720735781, 'eps': 8.529570863745659e-10, 'correct_bias': True, 'focal_gamma': 2.416753780361023, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:51:49,584] Trial 4 finished with value: 0.3201405107975006 and parameters: {'learning_rate': 6.56464770454095e-05, 'weight_decay': 0.001540773451136781, 'dropout_rate': 0.1723817375824085, 'batch_size': 64, 'early_stop_patience': 3, 'max_length': 128, 'gradient_clip': 0.8008832817655505, 'eps': 2.0832781747044625e-09, 'correct_bias': True, 'focal_gamma': 2.400171064835277, 'pos_weight': 2.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:53:49,385] Trial 5 finished with value: 0.22660799324512482 and parameters: {'learning_rate': 0.00013850813812236207, 'weight_decay': 0.0010412686152503807, 'dropout_rate': 0.48530946398409713, 'batch_size': 32, 'early_stop_patience': 2, 'max_length': 256, 'gradient_clip': 3.9645394424723794, 'eps': 2.5228211563870922e-08, 'correct_bias': False, 'focal_gamma': 3.1862786622794115, 'pos_weight': None}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 22:54:25,570] Trial 6 finished with value: 0.2900124490261078 and parameters: {'learning_rate': 3.432078503077648e-06, 'weight_decay': 0.0010349910623476896, 'dropout_rate': 0.10224583735658266, 'batch_size': 64, 'early_stop_patience': 3, 'max_length': 128, 'gradient_clip': 1.9642052862273967, 'eps': 8.226674867709433e-08, 'correct_bias': True, 'focal_gamma': 2.4735059474237886, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 23:00:00,741] Trial 7 finished with value: 0.32026636600494385 and parameters: {'learning_rate': 1.7943786324392427e-05, 'weight_decay': 0.00020120602858323804, 'dropout_rate': 0.18824578777556122, 'batch_size': 8, 'early_stop_patience': 5, 'max_length': 128, 'gradient_clip': 3.0225097256361027, 'eps': 2.88548961767127e-08, 'correct_bias': False, 'focal_gamma': 4.195188537075751, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 23:02:51,805] Trial 8 finished with value: 0.19749055802822113 and parameters: {'learning_rate': 3.83799917674195e-06, 'weight_decay': 0.004040501225419045, 'dropout_rate': 0.1235737397057239, 'batch_size': 16, 'early_stop_patience': 2, 'max_length': 64, 'gradient_clip': 2.892765361905016, 'eps': 6.257845657062278e-07, 'correct_bias': False, 'focal_gamma': 3.2344691154173075, 'pos_weight': 1.0}. Best is trial 0 with value: 0.10636131465435028.\n",
      "[I 2025-07-07 23:04:19,583] Trial 9 finished with value: 0.2604958117008209 and parameters: {'learning_rate': 0.0004216528554268635, 'weight_decay': 0.049359189811741463, 'dropout_rate': 0.16602857999868054, 'batch_size': 64, 'early_stop_patience': 2, 'max_length': 128, 'gradient_clip': 4.845003242776177, 'eps': 4.093935885834329e-07, 'correct_bias': True, 'focal_gamma': 1.2526537916787408, 'pos_weight': 5.0}. Best is trial 0 with value: 0.10636131465435028.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d2cb2898-4fa0-4405-be78-309f9f5496ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'learning_rate': 0.0001321776145528204, 'weight_decay': 0.00022122660751399764, 'dropout_rate': 0.47291614814623884, 'batch_size': 16, 'early_stop_patience': 4, 'max_length': 128, 'gradient_clip': 1.7413597427664174, 'eps': 3.785080347362386e-08, 'correct_bias': False, 'focal_gamma': 4.887162479562218, 'pos_weight': 2.0}\n",
      "Mejor valor de la métrica: 0.10636131465435028\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores hiperparámetros:\", study.best_params)\n",
    "print(\"Mejor valor de la métrica:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1ed0d05b-6bc4-42f0-8bda-cd9a7015431a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "focal_criterion = FocalLoss(gamma= 1.3640084425952896, pos_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b37ac406-6f31-4dfc-9490-dbb8d6c2f04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.0001321776145528204, 'weight_decay': 0.00022122660751399764, 'dropout_rate': 0.47291614814623884, 'batch_size': 16, 'early_stop_patience': 4, 'max_length': 128, 'gradient_clip': 1.7413597427664174, 'eps': 3.785080347362386e-08, 'correct_bias': False, 'focal_gamma': 4.887162479562218, 'pos_weight': 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f39c7b7b-e8f9-4e50-b65f-7315666c87c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MultiLabelNN(input_dim=5000, output_dim=y_train_multilabel.shape[1], dropout_rate=best_params['dropout_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bac3cf83-6527-461c-8848-2832cb17f89d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=best_params['learning_rate'],\n",
    "    weight_decay=best_params['weight_decay'],\n",
    "    eps=best_params['eps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c1166519-86e6-4d7e-95f1-e25a8a9175b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = FocalLoss(gamma=best_params['focal_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ba3fc0fa-6888-4d82-8d01-7bf13bd7631b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=best_params['batch_size'], \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3ed254bd-79cc-4771-8d8e-be258c251021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=best_params['batch_size'], \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "959c0e98-9456-4269-a163-feed284352c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "for epoch in range(int(best_params['eps'])+1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            model.parameters(), \n",
    "            best_params['gradient_clip']\n",
    "        )\n",
    "        \n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "108d9698-f17e-46bf-aced-c75d1ede5a8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelNN(\n",
       "  (fc1): Linear(in_features=5000, out_features=512, bias=True)\n",
       "  (dropout_rate): Dropout(p=0.16371488460446387, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9bb8e5d1-17f7-46c7-b1af-2c672c57933b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de data: torch.Size([16, 5000])\n",
      "Forma de labels: torch.Size([16, 9])\n",
      "Forma de outputs: torch.Size([16, 9])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, labels in val_loader:\n",
    "        outputs = model(data)\n",
    "        \n",
    "        print(f\"Forma de data: {data.shape}\")\n",
    "        print(f\"Forma de labels: {labels.shape}\")\n",
    "        print(f\"Forma de outputs: {outputs.shape}\")\n",
    "        break  # Solo el primer batch para ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ce13c1a5-0045-4128-8439-040501ebf4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78     13729\n",
      "           1       0.00      0.00      0.00      3961\n",
      "           2       0.00      0.00      0.00       726\n",
      "           3       0.00      0.00      0.00      5367\n",
      "           4       0.00      0.00      0.00      3263\n",
      "           5       0.40      0.08      0.13     14219\n",
      "           6       0.00      0.00      0.00       641\n",
      "           7       0.00      0.00      0.00      5579\n",
      "           8       0.00      0.00      0.00       793\n",
      "\n",
      "   micro avg       0.77      0.23      0.35     48278\n",
      "   macro avg       0.14      0.09      0.10     48278\n",
      "weighted avg       0.36      0.23      0.26     48278\n",
      " samples avg       0.25      0.23      0.24     48278\n",
      "\n",
      "Accuracy (exact match): 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, labels in val_loader:\n",
    "        outputs = model(data)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()  # Umbral de 0.5 para multi-etiqueta\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n",
    "all_labels = torch.cat(all_labels, dim=0).cpu().numpy()\n",
    "\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print(f\"Accuracy (exact match): {accuracy_score(all_labels, all_preds):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "8cbc3433-d3e7-4e33-89dd-0d6524993b75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81     13729\n",
      "           1       0.00      0.00      0.00      3206\n",
      "           2       0.00      0.00      0.00       667\n",
      "           3       0.00      0.00      0.00      4542\n",
      "           4       0.78      0.01      0.02      2756\n",
      "           5       0.41      0.92      0.57     13174\n",
      "           6       0.00      0.00      0.00       407\n",
      "           7       0.00      0.00      0.00      4431\n",
      "           8       0.00      0.00      0.00       498\n",
      "\n",
      "    accuracy                           0.54     43410\n",
      "   macro avg       0.22      0.19      0.16     43410\n",
      "weighted avg       0.43      0.54      0.43     43410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Obtener todas las predicciones\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, labels in val_loader:\n",
    "        outputs = model(data)\n",
    "        _, true_labels = torch.max(labels, 1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "print(classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f61420-d87a-4156-ba94-f556c88c89c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
